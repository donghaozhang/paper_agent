```latex
\subsection{Encoder}

The Encoder is a pivotal component of our proposed method, designed to convert raw input data, specifically images, into continuous latent representations through a Residual Network (ResNet) architecture. This architecture is chosen for its capability to efficiently capture high-level features while maintaining critical information necessary for subsequent quantization and reconstruction tasks.

\textbf{Input:} The input data is formatted as a tensor of shape \([B, C, H, W]\), where \(B\) denotes the batch size, \(C\) represents the number of channels, and \(H\) and \(W\) stand for the height and width of the images, respectively.

\textbf{Output:} The output of the Encoder consists of latent representations structured in a tensor of shape \([B, D, H', W']\), where \(D\) indicates the dimensionality of the latent space, and \(H'\), \(W'\) represent the spatial dimensions that result from the encoding process, typically reduced in size from the input dimensions.

\textbf{Workflow:}
\begin{enumerate}
    \item Initially, the raw input images undergo processing through a series of convolutional layers. Each layer employs convolutional filters, conducive to capturing hierarchical features at increasing levels of abstraction. Subsequent to the convolution, batch normalization is applied to stabilize the learning process, followed by the Leaky ReLU activation function, which introduces non-linearity into the model.
    \item The architecture incorporates residual blocks, which facilitate the learning of complex mappings from the input to the latent feature space. Each convolutional operation reduces the spatial dimensions while enhancing the depth of feature representations, allowing the model to encapsulate the essence of the data effectively.
    \item The final output from the Encoder generates a latent representation that is meticulously formatted for input into the Vector Quantizer. This ensures efficient quantization while preserving significant feature fidelity, critical for high-quality reconstructions in the subsequent Decoder stage.
\end{enumerate}

Formally, we represent the latent representation \(z_e\) generated by the Encoder as:

\begin{equation}
z_e = \text{Encoder}(x),
\end{equation}

where \(x\) signifies the input image. Each layer within the Encoder applies a transformation function \(f(\cdot)\), mathematically expressed as:

\begin{equation}
f(x) = \text{LeakyReLU}\left(\text{BatchNorm}\left(\text{Conv2D}(x)\right)\right).
\end{equation}

This formulation supports the extraction of hierarchical features crucial for subsequent representation learning, while simultaneously addressing gradient flow challenges through non-differentiable quantization layers.

To further enhance the performance of the Encoder, we implement a rotation and rescaling transformation process. This aims to optimize the alignment between the resulting encoded latent representations and the quantized embeddings within the codebook. This design consideration is essential for improved representation learning, as it mitigates issues such as codebook collapse and inefficient codebook utilization.

In conclusion, the robust design of the Encoder is fundamental for effective representation learning across the entire architecture, facilitating high-quality reconstructions in the Decoder stage. Subsequent sections will elaborate on the role of the Vector Quantizer in the discretization of the continuous representations generated by the Encoder and its critical contributions to the overall efficiency of the representation process.
```