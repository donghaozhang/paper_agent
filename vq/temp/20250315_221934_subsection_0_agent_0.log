```latex
\subsection{Encoder}

The Encoder component of our proposed method utilizes a Residual Network (ResNet) architecture to effectively process raw images and derive high-level features, transforming them into continuous latent representations. This strategic design allows for efficient data encoding while preserving essential information crucial for subsequent quantization and reconstruction tasks. The Encoder architecture comprises multiple convolutional layers, interwoven with residual blocks that enable the model to learn intricate mappings from the input data to the latent feature space.

\textbf{Input:} The raw input data, generally consisting of images, is formatted as a tensor of shape \([B, C, H, W]\), where \(B\) represents the batch size, \(C\) is the number of channels, and \(H\) and \(W\) denote the height and width of the images, respectively.

\textbf{Output:} The output of the Encoder consists of encoded latent representations with a shape of \([B, D, H', W']\), where \(D\) signifies the dimensionality of the latent space, and \(H'\) and \(W'\) are the spatial dimensions after the encoding process.

\textbf{Workflow:}
\begin{enumerate}
    \item The input images are passed through a series of convolutional layers, with each layer applying a convolutional filter followed by batch normalization and Leaky ReLU activation functions. The convolutional filters are purposefully tuned to capture hierarchical features at progressively advanced levels of abstraction.
    \item Each convolutional operation sequentially reduces the spatial dimensions of the input while augmenting the depth (number of feature channels), empowering the model to grasp the core characteristics of the data.
    \item The final output from the Encoder yields a latent representation that is suitably formatted for input into the Vector Quantizer, ensuring efficient quantization while maintaining significant feature fidelity.
\end{enumerate}

The architecture of the Encoder guarantees that the latent representations encapsulate the underlying structure of the input images, thus enabling downstream tasks such as quantization and reconstruction to function optimally. 

From a mathematical perspective, we can represent the latent representation \(z_e\) as follows:

\begin{equation}
z_e = \text{Encoder}(x), 
\end{equation}

where \(x\) is the input image. Each layer within the Encoder implements a transformation function \(f(\cdot)\), expressed as:

\begin{equation}
f(x) = \text{LeakyReLU}\left(\text{BatchNorm}\left(\text{Conv2D}(x)\right)\right).
\end{equation}

This formulation facilitates the extraction of hierarchical features, which are pivotal for the subsequent development of learned representations. 

In addressing challenges related to gradient propagation through the non-differentiable vector quantization layer, our Encoder also implements a rotation and rescaling transformation process. This enhancement optimizes the alignment between the encoded latent representations and the quantized embeddings within the codebook, thereby facilitating improved representation learning.

In summary, the robust design of the Encoder is fundamental to effective representation learning within the overall architecture, allowing for high-quality reconstructions in the subsequent Decoder stage. Subsequent sections will provide further details on the Vector Quantizer and its critical role in the discretization of the continuous representations generated by the Encoder.
```