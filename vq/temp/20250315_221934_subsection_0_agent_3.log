```latex
\subsection{Encoder}

The Encoder is a critical component of our proposed method, leveraging a Residual Network (ResNet) architecture to transform raw input images into continuous latent representations. This architecture is strategically selected for its ability to efficiently capture high-level features while preserving vital information necessary for the subsequent quantization and reconstruction processes.

\textbf{Input:} The input data is structured as a tensor of shape \([B, C, H, W]\), where \(B\) denotes the batch size, \(C\) represents the number of channels, and \(H\) and \(W\) indicate the height and width of the images, respectively.

\textbf{Output:} The output of the Encoder consists of latent representations organized in a tensor of shape \([B, D, H', W']\), where \(D\) signifies the dimensionality of the latent space and \(H'\), \(W'\) are the reduced spatial dimensions resulting from encoding.

\textbf{Architecture:} The Encoder employs a series of convolutional layers structured as follows:
\begin{itemize}
    \item Convolutional layer with 64 filters, kernel size 3, and stride 2
    \item Convolutional layer with 128 filters, kernel size 3, and stride 2
    \item Convolutional layer with 256 filters, kernel size 3, and stride 2
\end{itemize}

Each convolutional layer is succeeded by batch normalization to stabilize the learning process, along with the Leaky ReLU activation function, which introduces necessary non-linearity into the model. 

\textbf{Workflow:}
\begin{enumerate}
    \item The raw input images are processed through the aforementioned series of convolutional layers, with each layer designed to capture hierarchical features at increasing levels of abstraction.
    \item Residual connections are incorporated into the architecture, enabling the model to learn complex mappings from input images to the latent representation space more effectively. Each convolutional operation not only reduces spatial dimensions but also enhances the depth of feature representations, which is critical for accurate data encoding.
    \item The final output from the Encoder yields a latent representation formatted for input into the Vector Quantizer. This meticulous configuration supports efficient quantization while safeguarding significant feature fidelity, which is essential for achieving high-quality reconstructions in the subsequent Decoder stage.
\end{enumerate}

Formally, we represent the latent representation \(z_e\) generated by the Encoder as:

\begin{equation}
z_e = \text{Encoder}(x),
\end{equation}

where \(x\) denotes the input image. Each layer within the Encoder applies a transformation function \(f(\cdot)\) of the form:

\begin{equation}
f(x) = \text{LeakyReLU}\left(\text{BatchNorm}\left(\text{Conv2D}(x)\right)\right).
\end{equation}

This formulation facilitates the extraction of hierarchical features essential for subsequent representation learning, while simultaneously addressing gradient flow challenges related to the non-differentiability of quantization layers.

To further enhance the Encoder's performance, we incorporate a rotation and rescaling transformation process, designed to optimize the alignment between the generated encoded latent representations and the quantized embeddings within the codebook. This design consideration is pivotal for improving representation learning efficiency and mitigating issues such as codebook collapse and inefficient utilization.

In summary, the robust design of the Encoder is foundational for effective representation learning throughout the entire architecture, thereby enabling high-quality reconstructions in the Decoder stage. Subsequent sections will elaborate on the role of the Vector Quantizer in discretizing the continuous representations produced by the Encoder and its critical contributions to the overall efficiency of the representation process.
```