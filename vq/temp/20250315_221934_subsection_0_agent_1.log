```latex
\subsection{Encoder}

The Encoder component of our proposed method employs a Residual Network (ResNet) architecture to effectively process raw images and extract high-level features, transforming them into continuous latent representations. This architecture is strategically designed to facilitate efficient data encoding while preserving essential information that is critical for subsequent quantization and reconstruction tasks.

\textbf{Input:} The raw input data, typically consisting of images, is formatted as a tensor of shape \([B, C, H, W]\), where \(B\) represents the batch size, \(C\) is the number of channels, and \(H\) and \(W\) denote the height and width of the images, respectively.

\textbf{Output:} The output of the Encoder consists of encoded latent representations with a shape of \([B, D, H', W']\), where \(D\) signifies the dimensionality of the latent space, and \(H'\), \(W'\) represent the spatial dimensions after the encoding process.

\textbf{Workflow:}
\begin{enumerate}
    \item The input images are processed through a series of convolutional layers that utilize convolutional filters, followed by batch normalization and Leaky ReLU activation functions. These convolutional filters are tuned to capture hierarchical features at progressively advanced levels of abstraction.
    \item The architecture is enriched with residual blocks that facilitate the learning of intricate mappings from the input data to the latent feature space. Each convolutional operation reduces the spatial dimensions of the input while augmenting the depth, empowering the model to effectively grasp the core characteristics of the data.
    \item The final output from the Encoder generates a latent representation that is appropriately formatted for input into the Vector Quantizer, ensuring efficient quantization while maintaining significant feature fidelity.
\end{enumerate}

The encoder architecture is designed to ensure that the latent representations encapsulate the underlying structure of the input images, thus enabling downstream tasks such as quantization and reconstruction to function optimally. Formally, we can represent the latent representation \(z_e\) generated by the Encoder as follows:

\begin{equation}
z_e = \text{Encoder}(x), 
\end{equation}

where \(x\) represents the input image. Each layer within the Encoder implements a transformation function \(f(\cdot)\), expressed as:

\begin{equation}
f(x) = \text{LeakyReLU}\left(\text{BatchNorm}\left(\text{Conv2D}(x)\right)\right).
\end{equation}

This formulation not only facilitates the extraction of hierarchical features crucial for subsequent representation learning but also addresses the challenges associated with gradient propagation through non-differentiable quantization layers. To enhance this capability, our Encoder employs a rotation and rescaling transformation process, optimizing the alignment between the encoded latent representations and the quantized embeddings in the codebook. This contributes significantly to improved representation learning and avoids issues such as codebook collapse and limited codebook utilization.

In summary, the robust design of the Encoder is fundamental for effective representation learning within the entire architecture, allowing for high-quality reconstructions in the subsequent Decoder stage. Subsequent sections will outline the role of the Vector Quantizer in the discretization of the continuous representations generated by the Encoder and its critical contribution to achieving an efficient representation.
```