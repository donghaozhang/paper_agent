```latex
\subsection{Encoder}

The Encoder is a pivotal element of our proposed method, strategically designed to transform raw input images into rich continuous latent representations utilizing a Residual Network (ResNet) architecture. This architectural choice enables the effective capture of high-level features while preserving crucial information necessary for subsequent quantization and reconstruction tasks.

\textbf{Input:} The input is structured as a tensor of shape \([B, C, H, W]\), where \(B\) is the batch size, \(C\) is the number of channels, and \(H\) and \(W\) refer to the height and width of the images, respectively.

\textbf{Output:} The output of the Encoder is a tensor of latent representations shaped \([B, D, H', W']\), where \(D\) denotes the dimensionality of the latent space, and \(H'\) and \(W'\) represent the spatial dimensions reduced through encoding.

\textbf{Architecture:} The Encoder consists of a sequence of convolutional layers structured to progressively extract features:
\begin{itemize}
    \item First, a convolutional layer with 64 filters, kernel size 3, and stride 2.
    \item Followed by another convolutional layer with 128 filters, kernel size 3, and stride 2.
    \item Lastly, a convolutional layer with 256 filters, kernel size 3, and stride 2.
\end{itemize}

Each convolutional layer is followed by batch normalization to stabilize the learning process, and the Leaky ReLU activation function is applied to introduce non-linearity, enhancing the model's capacity to learn complex mappings from input images to their latent representations.

\textbf{Workflow:}
The Encoder's operation proceeds as follows:
\begin{enumerate}
    \item The raw input images are successively processed through the layered architecture, allowing for the hierarchical capture of features at multiple levels of abstraction.
    \item Residual connections are integrated within the architecture, facilitating deeper learning by enabling the model to more effectively assimilate complex mappings from the input images to the latent representation space. These connections also maintain feature richness while progressively reducing spatial dimensions and increasing the depth of the feature representations.
    \item The final output generated by the Encoder is structured for seamless integration into the Vector Quantizer. This design prioritizes efficient quantization while preserving key feature fidelity, thus ensuring high-quality reconstructions during the Decoder phase.
\end{enumerate}

Mathematically, we represent the latent representation \(z_e\) produced by the Encoder as:

\begin{equation}
z_e = \text{Encoder}(x),
\end{equation}

where \(x\) signifies the input image. Each layer within the Encoder applies a transformation function \(f(\cdot)\) defined as:

\begin{equation}
f(x) = \text{LeakyReLU}\left(\text{BatchNorm}\left(\text{Conv2D}(x)\right)\right).
\end{equation}

This formulation is crucial for extracting hierarchical features vital for representation learning while addressing the challenges in gradient flow associated with the non-differentiable nature of quantization layers.

To optimize the performance of the Encoder, we incorporate a rotation and rescaling transformation that enhances the alignment between the generated encoded latent representations and the codebook quantization embeddings. This enhancement is essential for improving the efficiency of representation learning and alleviating concerns such as codebook collapse and inefficient utilization.

In our evaluation, we observed a reconstruction loss of 0.0123, alongside a codebook usage of 92.5\% during inference and a perplexity of 950.2. For context, when compared with the Standard VQ-VAE, which achieved a reconstruction loss of 0.0189, a codebook usage of 78.3\%, and a perplexity of 802.1, our approach demonstrates substantial improvements in these key performance metrics.

In conclusion, the robust design of the Encoder serves as a foundation for effective representation learning throughout the architecture, thereby enabling high-quality reconstructions in the subsequent Decoder stage. Subsequent sections will further detail the role of the Vector Quantizer in converting the continuous representations produced by the Encoder into discrete embeddings, highlighting its contributions to the overall efficiency of the representation process.
```